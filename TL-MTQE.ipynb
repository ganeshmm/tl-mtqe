{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uIJm2C2Ywnh",
        "outputId": "0d404aa6-df86-41fa-88e9-2dd7b9f5086c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FcJusRCQQsdq"
      },
      "outputs": [],
      "source": [
        "# Install transformers module\n",
        "\n",
        "!pip install transformers\n",
        "\n",
        "\n",
        "\n",
        "!pip install sentencepiece\n",
        "!pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install my_library\n",
        "!mkdir my_data\n",
        "!wget my_url"
      ],
      "metadata": {
        "id": "cum-mnRDTDAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i447-aAGbuxZ"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import math\n",
        "import torch\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch import optim\n",
        "from functools import partial\n",
        "\n",
        "# BERT\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tqERpQ36w8Oj"
      },
      "outputs": [],
      "source": [
        "# Get Data from github \n",
        "# capture supresses output\n",
        "%%capture\n",
        "\n",
        "!mkdir data\n",
        "\n",
        "!wget -O en-de.tar.gz https://github.com/facebookresearch/mlqe/blob/main/data/en-de.tar.gz?raw=true\n",
        "!tar -xzvf en-de.tar.gz -C data\n",
        "\n",
        "!wget -O en-zh.tar.gz https://github.com/facebookresearch/mlqe/blob/main/data/en-zh.tar.gz?raw=true\n",
        "!tar -xzvf en-zh.tar.gz -C data\n",
        "\n",
        "!wget -O en-de.tar.gz https://github.com/facebookresearch/mlqe/blob/main/data/en-de_test.tar.gz?raw=true\n",
        "!tar -xzvf en-de.tar.gz -C data\n",
        "\n",
        "!wget -O en-zh.tar.gz https://github.com/facebookresearch/mlqe/blob/main/data/en-zh_test.tar.gz?raw=true\n",
        "!tar -xzvf en-zh.tar.gz -C data\n",
        "\n",
        "!wget -O ro-en.tar.gz https://github.com/facebookresearch/mlqe/blob/main/data/ro-en.tar.gz?raw=true\n",
        "!tar -xzvf ro-en.tar.gz -C data\n",
        "\n",
        "!wget -O et-en.tar.gz https://github.com/facebookresearch/mlqe/blob/main/data/et-en.tar.gz?raw=true\n",
        "!tar -xzvf et-en.tar.gz -C data\n",
        "\n",
        "!wget -O ne-en.tar.gz https://github.com/facebookresearch/mlqe/blob/main/data/ne-en.tar.gz?raw=true\n",
        "!tar -xzvf ne-en.tar.gz -C data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pNESChvVcSMz"
      },
      "outputs": [],
      "source": [
        "# Create dataframes with data, preprocess data\n",
        "\n",
        "# Main sets:\n",
        "df_en_de = pd.read_csv('data/en-de/train.ende.df.short.tsv', sep='\\t', error_bad_lines=False)\n",
        "df_en_zh = pd.read_csv('data/en-zh/train.enzh.df.short.tsv', sep='\\t', error_bad_lines=False)\n",
        "df_ro_en = pd.read_csv('data/ro-en/train.roen.df.short.tsv', sep='\\t', error_bad_lines=False)\n",
        "df_et_en = pd.read_csv('data/et-en/train.eten.df.short.tsv', sep='\\t', error_bad_lines=False)\n",
        "df_ne_en = pd.read_csv('data/ne-en/train.neen.df.short.tsv', sep='\\t', error_bad_lines=False)\n",
        "\n",
        "# Dev sets:\n",
        "df_en_de_dev = pd.read_csv('data/en-de/dev.ende.df.short.tsv', sep='\\t', error_bad_lines=False)\n",
        "df_en_zh_dev = pd.read_csv('data/en-zh/dev.enzh.df.short.tsv', sep='\\t', error_bad_lines=False)\n",
        "\n",
        "# Test sets:\n",
        "df_en_de_test = pd.read_csv('data/en-de/test20.ende.df.short.tsv', sep='\\t', error_bad_lines=False)\n",
        "df_en_zh_test = pd.read_csv('data/en-zh/test20.enzh.df.short.tsv', sep='\\t', error_bad_lines=False)\n",
        "\n",
        "# cleaning \n",
        "df_en_de = df_en_de.dropna()\n",
        "df_en_zh = df_en_zh.dropna()\n",
        "df_ro_en = df_ro_en.dropna()\n",
        "df_et_en = df_et_en.dropna()\n",
        "df_ne_en = df_ne_en.dropna()\n",
        "df_en_de_dev = df_en_de_dev.dropna()\n",
        "df_en_zh_dev = df_en_zh_dev.dropna()\n",
        "#df_en_de_test = df_en_de_test.dropna()\n",
        "#df_en_zh_test = df_en_zh_test.dropna()\n",
        "\n",
        "# Drop any pairs where either sentence is over half the length\n",
        "# This is a kinda bad way of preventing overflow in the training set\n",
        "\n",
        "#full_df = pd.concat([df_ro_en, df_et_en, df_ne_en, df_en_de, df_en_zh])\n",
        "#train_df = pd.concat([df_ro_en, df_et_en, df_ne_en, df_en_de_dev, df_en_zh_dev])\n",
        "#train_df = pd.concat([df_en_de])\n",
        "#train_df = pd.concat([df_en_zh])\n",
        "train_df = pd.concat([df_ro_en, df_et_en, df_ne_en, df_en_de_dev])\n",
        "#train_df = pd.concat([df_ro_en, df_et_en, df_ne_en, df_en_zh_dev])\n",
        "\n",
        "#test_df = pd.concat([df_en_de_test, df_en_zh_test])\n",
        "test_df = pd.concat([df_en_de_test])g\n",
        "#test_df = pd.concat([df_en_zh_test])\n",
        "#test_df = pd.concat([df_en_de, df_en_zh])\n",
        "\n",
        "# LOOKS LIKE THIS ISNT THE PROBLEM\n",
        "train_df = train_df.drop(train_df[\n",
        "   train_df['original'].apply(lambda x: len(x.split()) >= 128) |\n",
        "   train_df['translation'].apply(lambda x: len(x.split()) >= 128)\n",
        "].index)\n",
        "test_df = test_df.drop(test_df[\n",
        "   test_df['original'].apply(lambda x: len(x.split()) >= 128) |\n",
        "   test_df['translation'].apply(lambda x: len(x.split()) >= 128)\n",
        "].index)\n",
        "\n",
        "#x = train_df[\n",
        "#    train_df['original'].apply(lambda x: len(x.split()) >= 256) |\n",
        "#    train_df['translation'].apply(lambda x: len(x.split()) >= 256)\n",
        "#]\n",
        "\n",
        "#print(x)\n",
        "#print(x.split())\n",
        "#print(len(x.split()))\n",
        "#print(x.split(\"\\t\"))\n",
        "\n",
        "data = [train_df, test_df]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8rEYJl3NuNZ_"
      },
      "outputs": [],
      "source": [
        "def split(dataframes, train_test_split = .8, train_val_split = .75):\n",
        "  #if one dataframe, split into train, val, and test.\n",
        "  if len(dataframes) == 1:\n",
        "    full_data = dataframes[0]\n",
        "    num_rows = len(full_data)\n",
        "    print(f'Total rows in dataset: {num_rows}')\n",
        "\n",
        "    idxs = list(range(num_rows))\n",
        "    \n",
        "    markers = [\n",
        "      int(train_test_split * train_val_split * num_rows),\n",
        "      int(train_test_split * num_rows)\n",
        "    ]\n",
        "\n",
        "    train_idxs = idxs[:markers[0]]\n",
        "    val_idxs = idxs[markers[0]:markers[1]]\n",
        "    test_idxs = idxs[markers[1]:]\n",
        "\n",
        "    train_df = full_data.iloc[train_idxs].reset_index(drop=True)\n",
        "    val_df = full_data.iloc[val_idxs].reset_index(drop=True)\n",
        "    test_df = full_data.iloc[test_idxs].reset_index(drop=True)\n",
        "\n",
        "  #if two dataframes, split the first into train and val, use second as test.\n",
        "  elif len(dataframes) == 2:\n",
        "    train_val_df = dataframes[0]\n",
        "    test_df = dataframes[1]\n",
        "\n",
        "    num_rows = len(train_val_df) + len(test_df)\n",
        "    print(f'Total rows in dataset: {num_rows}')\n",
        "\n",
        "    idxs = list(range(len(train_val_df)))\n",
        "    \n",
        "    marker = int(train_val_split * len(train_val_df))\n",
        "\n",
        "    train_idxs = idxs[:marker]\n",
        "    val_idxs = idxs[marker:]\n",
        "\n",
        "    train_df = train_val_df.iloc[train_idxs].reset_index(drop=True)\n",
        "    val_df = train_val_df.iloc[val_idxs].reset_index(drop=True)\n",
        "\n",
        "  # if three dataframes, use as train, validation, and test (in order)\n",
        "  elif len(dataframes) == 3:\n",
        "    train_df = dataframes[0]\n",
        "    val_df = dataframes[1]\n",
        "    test_df = dataframes[2]\n",
        "\n",
        "    num_rows = len(train_df) + len(val_df) + len(test_df)\n",
        "    print(f'Total rows in dataset: {num_rows}')\n",
        "\n",
        "  else:\n",
        "    raise ValueError(\"Too many different dataframes\")\n",
        "\n",
        "  print(f'Train Split: {len(train_df)}')\n",
        "  print(f'Validation Split: {len(val_df)}')\n",
        "  print(f'Test Split: {len(test_df)}')\n",
        "\n",
        "  train_data = train_df[['index', 'original', 'translation', 'mean']]\n",
        "  val_data   = val_df[['index', 'original', 'translation', 'mean']]\n",
        "  test_data  = test_df[['index', 'original', 'translation', 'mean']]\n",
        "      \n",
        "  return train_data, val_data,test_data\n",
        "\n",
        "train_data, val_data, test_data = split(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XXvvccMmi8Zo"
      },
      "outputs": [],
      "source": [
        "class LanguageDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.df.iloc[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2FFR2emFvrwi"
      },
      "outputs": [],
      "source": [
        "train_dataset = LanguageDataset(train_data)\n",
        "val_dataset = LanguageDataset(val_data)\n",
        "test_dataset = LanguageDataset(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8jdcUnAnoOu7"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "EPOCHS = 6\n",
        "# EPOCHS= 10\n",
        "RNN_HIDDEN_SIZE = 256\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  \n",
        "print(\"Using device:\", device)\n",
        "\n",
        "#device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vEwaU5tZC1JI"
      },
      "outputs": [],
      "source": [
        "class QualityEstimator(nn.Module):\n",
        "    def __init__(self, rnn_hidden_size):\n",
        "        super(QualityEstimator, self).__init__()\n",
        "        self.rnn_hidden_size = rnn_hidden_size\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "        self.rnn = nn.LSTM(input_size=768, hidden_size=rnn_hidden_size, bidirectional=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(2*rnn_hidden_size, 128),\n",
        "            #nn.Linear(768, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1),\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        #freeze the BERT model:\n",
        "        for param in self.bert.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "    def forward(self, **x):\n",
        "        embeddings = self.bert(\n",
        "            input_ids = x[\"input_ids\"],\n",
        "            attention_mask= x[\"attention_mask\"],\n",
        "            token_type_ids = x[\"token_type_ids\"]\n",
        "            ).last_hidden_state\n",
        "        output, _ = self.rnn(embeddings)\n",
        "        l2r = self.flatten(output[:,-1,:self.rnn_hidden_size])\n",
        "        r2l = self.flatten(output[:,0,self.rnn_hidden_size:])\n",
        "        output = torch.cat((l2r, r2l), dim=-1)\n",
        "        #output = torch.mean(embeddings, dim=1)\n",
        "        logits = self.linear_relu_stack(output)\n",
        "        score = 100.0 * self.sigmoid(logits)\n",
        "        return score.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A_s33aFlGyOl"
      },
      "outputs": [],
      "source": [
        "#train a given model, using a pytorch dataloader, optimizer\n",
        "def train(model, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    size = 0\n",
        "    for input_ids, attention_mask, token_types, labels in tqdm(dataloader):\n",
        "        if input_ids is None:\n",
        "            pass\n",
        "        size += labels.shape[0]\n",
        "        output = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_types)\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= size\n",
        "    return train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_EpXaXf4Zs6f"
      },
      "outputs": [],
      "source": [
        "def test(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    \n",
        "    test_loss = 0.0\n",
        "    size = len(dataloader.dataset)\n",
        "    matrix = torch.zeros(2, size)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      with tqdm(dataloader, desc=\"Eval\", unit=\"batch\", total=len(dataloader)) as batch_iterator:\n",
        "        for i, (input_ids, attention_mask, token_types, labels) in enumerate(batch_iterator):\n",
        "            output = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_types)\n",
        "            test_loss += criterion(output, labels).item()\n",
        "\n",
        "            matrix[0,i*BATCH_SIZE:i*BATCH_SIZE+output.numel()] = output.flatten()\n",
        "            matrix[1,i*BATCH_SIZE:i*BATCH_SIZE+labels.numel()] = labels.flatten()\n",
        "\n",
        "    plt.scatter(matrix[0,:], matrix[1,:])\n",
        "    plt.show()\n",
        "\n",
        "    test_loss /= size\n",
        "    pearson = torch.corrcoef(matrix)[0,1]\n",
        "    return test_loss, pearson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "585bEzzmJnLQ"
      },
      "outputs": [],
      "source": [
        "#count the number of trainable parameters in the model\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "#computes the amount of time that a training epoch took and displays it in human readable form\n",
        "def epoch_time(start_time: int, end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1BtKiJyM9skH"
      },
      "outputs": [],
      "source": [
        "# SET UP MODEL\n",
        "model = QualityEstimator(RNN_HIDDEN_SIZE)\n",
        "\n",
        "model.train()\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GUpr5tIfdOxF"
      },
      "outputs": [],
      "source": [
        "mean = np.mean(train_data['mean'].astype(float))\n",
        "std = np.std(train_data['mean'].astype(float))\n",
        "print(mean)\n",
        "print(std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SZAOhgxNtKHS"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch, tokenizer):\n",
        "    input, masks, labels, types = [], [], [], []\n",
        "    for data in batch:\n",
        "        tokens = tokenizer(data['translation'], data['original'], return_tensors='pt')\n",
        "        if(tokens['input_ids'].shape[1]>256):\n",
        "          print(tokens, data['translation'], data['original'], float(data['mean']))\n",
        "          print(len(data['translation']), len(data['original']))\n",
        "        input.append(tokens['input_ids'].flatten())\n",
        "        masks.append(tokens['attention_mask'].flatten())\n",
        "        types.append(tokens['token_type_ids'].flatten())\n",
        "        labels.append(float(data['mean']))\n",
        "\n",
        "    input_ids = pad_sequence(input, batch_first=True).to(device)\n",
        "    attention_mask = pad_sequence(masks, batch_first=True).to(device)\n",
        "    token_types = pad_sequence(types, batch_first=True).to(device)\n",
        "\n",
        "    return input_ids, attention_mask, token_types, torch.tensor(labels).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-1Hiv_ofR0HK"
      },
      "outputs": [],
      "source": [
        "#help(BertTokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nx2AHHoWU1qd"
      },
      "outputs": [],
      "source": [
        "#def collate_fn(batch, tokenizer):\n",
        "#    src_input, tar_input, src_masks, tar_masks, labels = [], [], [], [], []\n",
        "#    for data in batch:\n",
        "#        src_tokens = tokenizer(data['original'], return_tensors='pt')\n",
        "#        tar_tokens = tokenizer(data['translation'], return_tensors='pt')\n",
        "#\n",
        "#        src_input.append(src_tokens['input_ids'].flatten())\n",
        "#        src_masks.append(src_tokens['attention_mask'].flatten())\n",
        "#\n",
        "#        tar_input.append(tar_tokens['input_ids'].flatten())\n",
        "#        tar_masks.append(tar_tokens['attention_mask'].flatten())\n",
        "#        labels.append(float(data['mean']))\n",
        "#    \n",
        "#    input = src_input + tar_input\n",
        "#    input = pad_sequence(input, batch_first=True).to(device)\n",
        "#    \n",
        "#    attention_mask = src_masks + tar_masks\n",
        "#    attention_mask = pad_sequence(attention_mask, batch_first=True).to(device)\n",
        "#    return input[input.shape[0]//2:].to(device), attention_mask[input.shape[0]//2:].to(device), torch.tensor(labels).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fJJwVn2wBLqv"
      },
      "outputs": [],
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss(reduction=reduction)\n",
        "        self.eps = eps\n",
        "    \n",
        "    def forward(self, input, target):\n",
        "        return torch.sqrt(self.mse(input, target) + self.eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tWbTl63y9w-r"
      },
      "outputs": [],
      "source": [
        "# SET UP OTHER STUFF\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Initialize DataLoader\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=BATCH_SIZE,collate_fn=partial(collate_fn, tokenizer=tokenizer), shuffle = True)\n",
        "val_dataloader = DataLoader(val_dataset,batch_size=BATCH_SIZE,collate_fn=partial(collate_fn, tokenizer=tokenizer), shuffle = True)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=BATCH_SIZE,collate_fn=partial(collate_fn, tokenizer=tokenizer), shuffle = True)\n",
        "\n",
        "# set up train loop\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.MSELoss(reduction='sum')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "42mp5U54nFUi"
      },
      "outputs": [],
      "source": [
        "def examples(model, df, tokenizer, num_examples):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_examples):\n",
        "            idx = torch.randint(len(df), (1, 1)).item()\n",
        "            source = df.iloc[idx]['original']\n",
        "            translation = df.iloc[idx]['translation']\n",
        "            mean = float(df.iloc[idx]['mean'])\n",
        "            encoded_input = tokenizer(translation, source, return_tensors='pt', max_length = 512).to(device)\n",
        "            output = model(\n",
        "                input_ids=encoded_input['input_ids'].flatten().unsqueeze(0), \n",
        "                attention_mask=encoded_input['attention_mask'].flatten().unsqueeze(0),\n",
        "                token_type_ids=encoded_input['token_type_ids'].flatten().unsqueeze(0)\n",
        "            )\n",
        "\n",
        "            print('source:', source)\n",
        "            print('translation:', translation)\n",
        "            print('output:', output.item())\n",
        "            print('mean:', mean)\n",
        "            print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lGsWUFsBFmKM"
      },
      "outputs": [],
      "source": [
        "#NEEEEEEEEEEEEEEEEEEEEEEEEW\n",
        "epoch_loss = []\n",
        "validation_loss = []\n",
        "accuracy = []\n",
        "\n",
        "#count number of params\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "# train_loss = evaluate(model, train_dataloader, criterion, device)\n",
        "# print(f'Initial Train Loss: {train_loss:.3f}')\n",
        "\"\"\"\n",
        "train_acc = evaluate_acc(model, train_dataloader, device)\n",
        "print(f'Initial Train Acc: {train_acc:.3f}')\n",
        "\n",
        "valid_loss = evaluate(model, val_dataloader, criterion, device)\n",
        "print(f'Initial Valid Loss: {valid_loss:.3f}')\n",
        "\n",
        "valid_acc = evaluate_acc(model, val_dataloader, device)\n",
        "print(f'Initial Valid Acc: {valid_acc:.3f}')\n",
        "\n",
        "epoch_loss.append(train_loss)\n",
        "validation_loss.append(valid_loss)\n",
        "\"\"\"\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_dataloader, criterion, optimizer)\n",
        "    end_time = time.time()\n",
        "    valid_loss, valid_pearson = test(model, val_dataloader, criterion)\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\tValid Loss: {valid_loss:.3f}')\n",
        "    print(f'\\tValid Acc: {valid_pearson:.3f}')\n",
        "\n",
        "    examples(model, test_data, tokenizer, 2)\n",
        "\n",
        "    epoch_loss.append(train_loss)\n",
        "    validation_loss.append(valid_loss)\n",
        "    accuracy.append(valid_pearson)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_VfL-0t518U"
      },
      "outputs": [],
      "source": [
        "test_acc, test_pearson = test(model, test_dataloader, criterion)\n",
        "print(f'Final Test Acc: {test_pearson:.3f}')\n",
        "\n",
        "plt.plot(epoch_loss)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OsgXOL2o9ak"
      },
      "outputs": [],
      "source": [
        "examples(model, test_data, tokenizer, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owrQic9gnt9L"
      },
      "outputs": [],
      "source": [
        "plt.plot(epoch_loss)\n",
        "plt.plot(validation_loss)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOJMCFjnkPsc"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "fig = go.Figure(\n",
        "    layout_title_text=\"A Figure Displayed with the 'colab' Renderer\"\n",
        ")\n",
        "fig.add_trace(go.Line(\n",
        "    y=accuracy[1:],\n",
        "    name=\"Training Pearson\"       # this sets its legend entry\n",
        "))\n",
        "# fig.add_trace(go.Bar(\n",
        "#     y=[test_acc],\n",
        "#     name=\"Test Acc\"       # this sets its legend entry\n",
        "# ))\n",
        "fig.update_layout(\n",
        "    title=\"Pearson German/German\",\n",
        "    xaxis_title=\"Epoch\",\n",
        "    yaxis_title=\"Training Pearson\"\n",
        ")\n",
        "fig.show(renderer=\"colab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VnXKJQHkQDH"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "fig = go.Figure(\n",
        "    layout_title_text=\"A Figure Displayed with the 'colab' Renderer\"\n",
        ")\n",
        "fig.add_trace(go.Line(\n",
        "    y=epoch_loss[1:],\n",
        "    name=\"Training Loss\"       # this sets its legend entry\n",
        "))\n",
        "fig.add_trace(go.Line(\n",
        "    y=validation_loss[1:],\n",
        "    name=\"Validation Loss\"       # this sets its legend entry\n",
        "))\n",
        "fig.update_layout(\n",
        "    title=\"Loss(RMSE) German/German\",\n",
        "    xaxis_title=\"Epoch\",\n",
        "    yaxis_title=\"Training Loss\"\n",
        ")\n",
        "fig.show(renderer=\"colab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFLndQ1mqDM3"
      },
      "outputs": [],
      "source": [
        "print(epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSzTle_NtOhh"
      },
      "outputs": [],
      "source": [
        "test_dataset_en_de = LanguageDataset(df_en_de)\n",
        "test_dataset_en_zh = LanguageDataset(df_en_zh)\n",
        "test_en_de_dataloader = DataLoader(test_dataset_en_de,batch_size=BATCH_SIZE,collate_fn=partial(collate_fn, tokenizer=tokenizer), shuffle = True)\n",
        "test_en_zh_dataloader = DataLoader(test_dataset_en_zh,batch_size=BATCH_SIZE,collate_fn=partial(collate_fn, tokenizer=tokenizer), shuffle = True)\n",
        "\n",
        "test_acc, test_pearson = test(model, test_en_de_dataloader, criterion)\n",
        "print(f'Final Test En De Pearson: {test_pearson:.3f}')\n",
        "\n",
        "test_acc, test_pearson = test(model, test_en_de_dataloader, criterion)\n",
        "print(f'Final Test En Zh Pearson: {test_pearson:.3f}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}